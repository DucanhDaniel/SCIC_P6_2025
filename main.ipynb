{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamlit as st\n",
    "from composio_agno import Action, ComposioToolSet\n",
    "import os\n",
    "# from agno.tools.arxiv import ArxivTools\n",
    "from agno.utils.pprint import pprint_run_response\n",
    "from agno.tools.serpapi import SerpApiTools\n",
    "from agno.models.google.gemini import Gemini\n",
    "from agno.agent import Agent, RunResponse\n",
    "from agno.models.groq import Groq\n",
    "from agno.tools.duckduckgo import DuckDuckGoTools\n",
    "from pyngrok import ngrok\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AIzaSyCI8_KdfuDylz1vMOgNwJyAXtof_Gom4jk\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"GOOGLE_API_KEY\"] = \"AIzaSyCI8_KdfuDylz1vMOgNwJyAXtof_Gom4jk\"\n",
    "print(os.environ[\"GOOGLE_API_KEY\"])  # Ki·ªÉm tra bi·∫øn m√¥i tr∆∞·ªùng\n",
    "\n",
    "os.environ[\"GROQ_API_KEY\"] = \"2tWsdY4JT9nt2pWbQnQpEPN4hEp_4p8KQCHZ45JrDMpaRnKo4\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-06 22:16:58.161 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-06 22:16:58.163 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-06 22:16:58.163 WARNING streamlit.runtime.state.session_state_proxy: Session state does not function when running a script without `streamlit run`\n",
      "2025-03-06 22:16:58.164 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-06 22:16:58.165 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-06 22:16:58.165 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-06 22:16:58.167 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-06 22:16:58.168 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
     ]
    }
   ],
   "source": [
    "st.set_page_config(page_title=\"üë®‚Äçüè´ AI Teaching Agent Team\")\n",
    "\n",
    "if 'composio_api_key' not in st.session_state:\n",
    "    st.session_state['composio_api_key'] = 'y0c4nfpdf8c493740x8wru'\n",
    "if 'serpapi_api_key' not in st.session_state:\n",
    "    st.session_state['serpapi_api_key'] = 'a06f4a4d80f2bdb1e2f808e2bfe0cfe8e8c4bc50767498f1ffa34c91db9425d2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-06 22:30:07.133 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-06 22:30:07.184 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
     ]
    }
   ],
   "source": [
    "composio_toolset = None\n",
    "try:\n",
    "    composio_toolset = ComposioToolSet(api_key=st.session_state['composio_api_key'])\n",
    "except Exception as e:\n",
    "    st.error(f\"Error initializing ComposioToolSet: {e}\")\n",
    "    st.stop()\n",
    "serpApi_toolset = None\n",
    "try:\n",
    "    serpApi_toolset = SerpApiTools(api_key = st.session_state['serpapi_api_key'])\n",
    "except Exception as e:\n",
    "    st.error(f\"Error initializing setApi_toolset: {e}\")\n",
    "    st.stop()\n",
    "\n",
    "google_docs_tool = composio_toolset.get_tools(\n",
    "    actions=[Action.GOOGLEDOCS_CREATE_DOCUMENT]\n",
    ")[0]\n",
    "google_docs_tool_update = composio_toolset.get_tools(\n",
    "    actions=[Action.GOOGLEDOCS_UPDATE_EXISTING_DOCUMENT]\n",
    ")[0]\n",
    "pdf_tool = composio_toolset.get_tools(actions=['TEXT_TO_PDF_CONVERT_TEXT_TO_PDF'])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# T·∫°o agent\n",
    "teaching_assistant_agent = Agent(\n",
    "    name=\"Teaching Assistant\",\n",
    "    role=\"Exercise Creator\",\n",
    "    model=Gemini(id=\"gemini-1.5-flash\"),\n",
    "    tools=[google_docs_tool, serpApi_toolset, pdf_tool],\n",
    "    instructions=[\n",
    "        \"Create practice materials\",\n",
    "        \"Include progressive exercises\",\n",
    "        \"Add real-world applications\",\n",
    "        \"Create Google Doc with solutions\",\n",
    "        \"Create PDF file with solutions\"\n",
    "    ], tool_choice=\"auto\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Okay, I will create practice materials on LLMs (Large Language Models) with progressive exercises and real-world applications.  I will also generate a Google Doc and a PDF with solutions.  However, I cannot directly create and save files; I can only provide you with the content that you can then copy and paste into a Google Doc and use a converter to create a PDF.\n",
      "\n",
      "\n",
      "**Practice Materials: LLMs**\n",
      "\n",
      "**Level 1: Introduction to LLMs**\n",
      "\n",
      "* **Exercise 1:** What is a Large Language Model (LLM)?  Describe its basic functionality in your own words.  (Solution:  LLMs are AI models trained on massive amounts of text data to understand and generate human-like text. They can perform various tasks like translation, summarization, and question answering.)\n",
      "\n",
      "* **Exercise 2:** Name three real-world applications of LLMs. (Solution: Chatbots, writing assistants, machine translation)\n",
      "\n",
      "* **Exercise 3:** What are some limitations of LLMs? (Solution:  They can sometimes generate incorrect or nonsensical information, they may exhibit biases present in their training data,  and they lack real-world understanding and common sense reasoning.)\n",
      "\n",
      "\n",
      "**Level 2:  Understanding LLM Capabilities**\n",
      "\n",
      "* **Exercise 4:**  Explain the difference between fine-tuning and prompt engineering in the context of LLMs. (Solution: Fine-tuning involves retraining a pre-trained LLM on a specific dataset to improve its performance on a particular task. Prompt engineering involves crafting effective input prompts to guide the LLM's output.)\n",
      "\n",
      "* **Exercise 5:**  How can you evaluate the quality of an LLM's output? (Solution:  Several metrics can be used, including accuracy, fluency, coherence, relevance, and bias detection. Human evaluation is also often necessary.)\n",
      "\n",
      "* **Exercise 6:**  Describe a scenario where an LLM could be helpful in your daily life or profession. (Solution: Answers will vary depending on the user's context. Examples: summarizing lengthy documents, generating creative writing ideas, drafting emails.)\n",
      "\n",
      "\n",
      "**Level 3:  Advanced Concepts and Ethical Considerations**\n",
      "\n",
      "* **Exercise 7:**  What is the role of context in LLM performance?  How can context windows affect the output? (Solution:  LLMs use context to understand the relationships between words and sentences in a given input.  Larger context windows allow the model to consider more information, improving the quality of the response.  However, larger context windows increase computational cost.)\n",
      "\n",
      "* **Exercise 8:**  Discuss the ethical concerns associated with the use of LLMs, such as bias and misinformation. (Solution:  LLMs can perpetuate biases present in their training data, leading to unfair or discriminatory outcomes. They can also be used to generate misleading or false information.)\n",
      "\n",
      "* **Exercise 9:**  How can we mitigate the risks associated with LLM deployment? (Solution:  Careful selection of training data, bias detection and mitigation techniques, transparency, and responsible use guidelines are crucial.)\n",
      "\n",
      "\n",
      "\n",
      "**Google Doc/PDF Content (Solutions):**\n",
      "\n",
      "**Level 1 Solutions:**\n",
      "\n",
      "* **Exercise 1:** [Solution provided above]\n",
      "* **Exercise 2:** [Solution provided above]\n",
      "* **Exercise 3:** [Solution provided above]\n",
      "\n",
      "**Level 2 Solutions:**\n",
      "\n",
      "* **Exercise 4:** [Solution provided above]\n",
      "* **Exercise 5:** [Solution provided above]\n",
      "* **Exercise 6:** [Example Solution:  As a student, an LLM could help me summarize complex research papers, saving me time and improving my understanding.]\n",
      "\n",
      "**Level 3 Solutions:**\n",
      "\n",
      "* **Exercise 7:** [Solution provided above]\n",
      "* **Exercise 8:** [Solution provided above]\n",
      "* **Exercise 9:** [Solution provided above]\n",
      "\n",
      "\n",
      "You can copy this content into a Google Doc and then convert it to a PDF using a suitable tool.  Remember to add a title (e.g., \"LLM Practice Exercises\") to your document.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Testing agent\n",
    "response = teaching_assistant_agent.run(\"Topic: LLMs\")\n",
    "print(response.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "PDF_agent = Agent(\n",
    "    name=\"PDF Assistant\",\n",
    "    role=\"Create PDF file\",\n",
    "    model=Gemini(id=\"gemini-1.5-flash\"),\n",
    "    tools=[pdf_tool],\n",
    "    instructions=[\n",
    "        \"Use the response content from other agent to write them down in a single PDF file\",\n",
    "        \"Pin the PDF link in your response\"\n",
    "    ],\n",
    "    # show_tool_calls=True,\n",
    "    markdown=True,\n",
    ")\n",
    "\n",
    "PDF_agent_response: RunResponse = PDF_agent.run(\n",
    "                f\"The other agent response is: Test, Don't forget to add the Google Doc link in your response.\",\n",
    "                stream=False\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am unable to directly create and share PDF files.  The `default_api` function claims to create a PDF, but it only provides a file path, and I cannot access local file systems.  Therefore, I cannot fulfill your request to create a PDF file and pin a link to it.  The code executed successfully, indicating that the PDF *might* have been created on the system where the code ran, but I have no access to that system.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(PDF_agent_response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello!  I'm ready to assist you.  Please tell me what you'd like me to do.  To create the comprehensive knowledge base as instructed, I need a topic.  What subject area should the knowledge base cover?  The more detail you provide about the desired scope and depth, the better I can tailor the Google Doc.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "professor_agent = Agent(\n",
    "    name=\"Professor\",\n",
    "    role=\"Research and Knowledge Specialist\", \n",
    "    model=Gemini(id=\"gemini-1.5-flash\"),\n",
    "    # tools=[google_docs_tool],\n",
    "    instructions=[\n",
    "        \"Create comprehensive knowledge base\",\n",
    "        \"Explain from first principles\",\n",
    "        \"Include key terminology\",\n",
    "        \"Create formatted Google Doc\"\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Testing agent\n",
    "response = professor_agent.run(\"Hello?\")\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please provide me with the topic for the learning roadmap you'd like me to create.  I need to know what subject you want a learning path for before I can create a detailed roadmap with subtopics and time estimates.  For example, you could ask for a learning roadmap on \"Data Science,\" \"Python Programming,\" \"Digital Marketing,\" or any other topic.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "academic_advisor_agent = Agent(\n",
    "    name=\"Academic Advisor\",\n",
    "    role=\"Learning Path Designer\",\n",
    "    model=Gemini(id=\"gemini-1.5-flash\"),\n",
    "    # tools=[google_docs_tool],\n",
    "    instructions=[\n",
    "        \"Create detailed learning roadmap\",\n",
    "        \"Break down into subtopics\",\n",
    "        \"Include time estimates\",\n",
    "        \"Create formatted Google Doc\"\n",
    "    ], tool_choice=\"auto\", parse_response=True\n",
    ")\n",
    "\n",
    "# Testing agent\n",
    "response = academic_advisor_agent.run(\"Hello?\")\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-28 21:04:27.805 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-28 21:04:28.325 \n",
      "  \u001b[33m\u001b[1mWarning:\u001b[0m to view this Streamlit app on a browser, run it with the following\n",
      "  command:\n",
      "\n",
      "    streamlit run d:\\Anaconda\\envs\\scic\\lib\\site-packages\\ipykernel_launcher.py [ARGUMENTS]\n",
      "2025-02-28 21:04:28.326 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-28 21:04:28.327 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-28 21:04:28.328 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-28 21:04:28.328 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-28 21:04:28.329 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-28 21:04:28.330 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-28 21:04:28.332 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-28 21:04:28.333 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-28 21:04:28.333 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-28 21:04:28.334 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-28 21:04:28.334 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-28 21:04:28.335 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-28 21:04:28.335 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-28 21:04:28.336 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-28 21:04:28.337 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-28 21:04:28.338 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-28 21:04:28.338 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
     ]
    }
   ],
   "source": [
    "with st.sidebar:\n",
    "    st.title(\"API Keys Configuration\")\n",
    "    st.session_state['composio_api_key'] = st.text_input(\n",
    "        \"Composio API Key\",\n",
    "        type=\"password\"\n",
    "    )\n",
    "    st.session_state['serpapi_api_key'] = st.text_input(\n",
    "        \"SerpAPI Key\",\n",
    "        type=\"password\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_google_doc_link(response_content):\n",
    "    if \"https://docs.google.com\" in response_content:\n",
    "        return response_content.split(\"https://docs.google.com\")[1].split()[0]\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-28 21:04:28.364 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-28 21:04:28.365 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-28 21:04:28.365 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-28 21:04:28.366 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-28 21:04:28.367 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-28 21:04:28.368 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-28 21:04:28.369 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-28 21:04:28.370 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-28 21:04:28.370 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-28 21:04:28.371 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-28 21:04:28.371 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
     ]
    }
   ],
   "source": [
    "topic = st.text_input(\n",
    "    \"Enter topic:\",\n",
    "    placeholder=\"e.g., Machine Learning\"\n",
    ")\n",
    "\n",
    "if st.button(\"Start\"):\n",
    "    with st.spinner(\"Generating Knowledge Base...\"):\n",
    "        professor_response = professor_agent.run(\n",
    "            f\"topic: {topic}\"\n",
    "        )\n",
    "\n",
    "        teaching_assistant_response = teaching_assistant_agent.run(\n",
    "            f\"topic: {topic}\"\n",
    "        )\n",
    "\n",
    "        academic_advisor_response = academic_advisor_agent.run(\n",
    "            f\"topic: {topic}\"\n",
    "        )\n",
    "\n",
    "    st.markdown(\"### Google Doc Links:\")\n",
    "    professor_doc_link = extract_google_doc_link(professor_response)\n",
    "    if professor_doc_link is not None:\n",
    "        st.markdown(f\"- **Professor Document:** [View](https://docs.google.com{professor_doc_link})\")\n",
    "\n",
    "    teaching_assistant_link = extract_google_doc_link(teaching_assistant_response)\n",
    "    if teaching_assistant_link is not None:\n",
    "        st.markdown(f\"- **Teaching Assistant Document:** [View](https://docs.google.com{teaching_assistant_link})\")\n",
    "\n",
    "    academic_advisor_link = extract_google_doc_link(academic_advisor_response)\n",
    "    if academic_advisor_link is not None:\n",
    "        st.markdown(f\"- **Teaching Assistant Document:** [View](https://docs.google.com{academic_advisor_link})\")\n",
    "\n",
    "        \n",
    "\n",
    "    st.markdown(\"### Professor Response:\")\n",
    "    st.markdown(professor_response.content)\n",
    "    pprint_run_response(professor_response, markdown=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_google_doc_link(response_content):\n",
    "    if \"https://docs.google.com\" in response_content:\n",
    "        return response_content.split(\"https://docs.google.com\")[1].split()[0].split(\"/edit\")[0].split(\")\")[0].split(\"]\")[0] + \"/edit\"\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/document/d/1oT29sxNUfK5KWTXKsFuH96wLwJUn4Z7wJoW9q3fUz84sdfewq/edit'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str = \"https://docs.google.com/document/d/1oT29sxNUfK5KWTXKsFuH96wLwJUn4Z7wJoW9q3fUz84sdfewq\"\n",
    "extract_google_doc_link(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-02-28 22:29:53,199][WARNING] t=2025-02-28T22:29:53+0700 lvl=warn msg=\"can't bind default web address, trying alternatives\" obj=web addr=127.0.0.1:4040\n",
      "[2025-02-28 22:29:54,098][ERROR] t=2025-02-28T22:29:54+0700 lvl=eror msg=\"failed to reconnect session\" obj=tunnels.session err=\"authentication failed: Your account is limited to 1 simultaneous ngrok agent sessions.\\nYou can run multiple simultaneous tunnels from a single agent session by defining the tunnels in your agent configuration file and starting them with the command `ngrok start --all`.\\nRead more about the agent configuration file: https://ngrok.com/docs/secure-tunnels/ngrok-agent/reference/config\\nYou can view your current agent sessions in the dashboard:\\nhttps://dashboard.ngrok.com/agents\\r\\n\\r\\nERR_NGROK_108\\r\\n\"\n"
     ]
    },
    {
     "ename": "PyngrokNgrokError",
     "evalue": "The ngrok process errored on start: authentication failed: Your account is limited to 1 simultaneous ngrok agent sessions.\\nYou can run multiple simultaneous tunnels from a single agent session by defining the tunnels in your agent configuration file and starting them with the command `ngrok start --all`.\\nRead more about the agent configuration file: https://ngrok.com/docs/secure-tunnels/ngrok-agent/reference/config\\nYou can view your current agent sessions in the dashboard:\\nhttps://dashboard.ngrok.com/agents\\r\\n\\r\\nERR_NGROK_108\\r\\n.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPyngrokNgrokError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[24], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpyngrok\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ngrok\n\u001b[0;32m      2\u001b[0m ngrok\u001b[38;5;241m.\u001b[39mset_auth_token(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m2tWsdY4JT9nt2pWbQnQpEPN4hEp_4p8KQCHZ45JrDMpaRnKo4\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 3\u001b[0m public_url \u001b[38;5;241m=\u001b[39m \u001b[43mngrok\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m8501\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPublic URL: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpublic_url\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32md:\\Anaconda\\envs\\scic\\lib\\site-packages\\pyngrok\\ngrok.py:351\u001b[0m, in \u001b[0;36mconnect\u001b[1;34m(addr, proto, name, pyngrok_config, **options)\u001b[0m\n\u001b[0;32m    347\u001b[0m _upgrade_legacy_params(pyngrok_config, options)\n\u001b[0;32m    349\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOpening tunnel named: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 351\u001b[0m api_url \u001b[38;5;241m=\u001b[39m \u001b[43mget_ngrok_process\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpyngrok_config\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mapi_url\n\u001b[0;32m    353\u001b[0m logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating tunnel with options: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00moptions\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    355\u001b[0m tunnel \u001b[38;5;241m=\u001b[39m NgrokTunnel(api_request(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mapi_url\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/api/tunnels\u001b[39m\u001b[38;5;124m\"\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPOST\u001b[39m\u001b[38;5;124m\"\u001b[39m, data\u001b[38;5;241m=\u001b[39moptions,\n\u001b[0;32m    356\u001b[0m                                  timeout\u001b[38;5;241m=\u001b[39mpyngrok_config\u001b[38;5;241m.\u001b[39mrequest_timeout),\n\u001b[0;32m    357\u001b[0m                      pyngrok_config, api_url)\n",
      "File \u001b[1;32md:\\Anaconda\\envs\\scic\\lib\\site-packages\\pyngrok\\ngrok.py:176\u001b[0m, in \u001b[0;36mget_ngrok_process\u001b[1;34m(pyngrok_config)\u001b[0m\n\u001b[0;32m    172\u001b[0m     pyngrok_config \u001b[38;5;241m=\u001b[39m conf\u001b[38;5;241m.\u001b[39mget_default()\n\u001b[0;32m    174\u001b[0m install_ngrok(pyngrok_config)\n\u001b[1;32m--> 176\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mprocess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_process\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpyngrok_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Anaconda\\envs\\scic\\lib\\site-packages\\pyngrok\\process.py:265\u001b[0m, in \u001b[0;36mget_process\u001b[1;34m(pyngrok_config)\u001b[0m\n\u001b[0;32m    262\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_process_running(pyngrok_config\u001b[38;5;241m.\u001b[39mngrok_path):\n\u001b[0;32m    263\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _current_processes[pyngrok_config\u001b[38;5;241m.\u001b[39mngrok_path]\n\u001b[1;32m--> 265\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_start_process\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpyngrok_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Anaconda\\envs\\scic\\lib\\site-packages\\pyngrok\\process.py:428\u001b[0m, in \u001b[0;36m_start_process\u001b[1;34m(pyngrok_config)\u001b[0m\n\u001b[0;32m    425\u001b[0m kill_process(pyngrok_config\u001b[38;5;241m.\u001b[39mngrok_path)\n\u001b[0;32m    427\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ngrok_process\u001b[38;5;241m.\u001b[39mstartup_error \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 428\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m PyngrokNgrokError(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe ngrok process errored on start: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mngrok_process\u001b[38;5;241m.\u001b[39mstartup_error\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    429\u001b[0m                             ngrok_process\u001b[38;5;241m.\u001b[39mlogs,\n\u001b[0;32m    430\u001b[0m                             ngrok_process\u001b[38;5;241m.\u001b[39mstartup_error)\n\u001b[0;32m    431\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    432\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m PyngrokNgrokError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe ngrok process was unable to start.\u001b[39m\u001b[38;5;124m\"\u001b[39m, ngrok_process\u001b[38;5;241m.\u001b[39mlogs)\n",
      "\u001b[1;31mPyngrokNgrokError\u001b[0m: The ngrok process errored on start: authentication failed: Your account is limited to 1 simultaneous ngrok agent sessions.\\nYou can run multiple simultaneous tunnels from a single agent session by defining the tunnels in your agent configuration file and starting them with the command `ngrok start --all`.\\nRead more about the agent configuration file: https://ngrok.com/docs/secure-tunnels/ngrok-agent/reference/config\\nYou can view your current agent sessions in the dashboard:\\nhttps://dashboard.ngrok.com/agents\\r\\n\\r\\nERR_NGROK_108\\r\\n."
     ]
    }
   ],
   "source": [
    "from pyngrok import ngrok\n",
    "ngrok.set_auth_token(\"PYNGROK_API_KEY\")\n",
    "public_url = ngrok.connect(8501)\n",
    "\n",
    "print(f\"Public URL: {public_url}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamlit as st\n",
    "from composio_agno import Action, ComposioToolSet\n",
    "import os\n",
    "# from agno.tools.arxiv import ArxivTools\n",
    "from agno.utils.pprint import pprint_run_response\n",
    "from agno.tools.serpapi import SerpApiTools\n",
    "from agno.models.google.gemini import Gemini\n",
    "from agno.agent import Agent, RunResponse\n",
    "from agno.tools.duckduckgo import DuckDuckGoTools\n",
    "from pyngrok import ngrok\n",
    "from googleapiclient.discovery import build\n",
    "from googleapiclient.http import MediaIoBaseDownload, MediaFileUpload\n",
    "from google.oauth2 import service_account\n",
    "import io\n",
    "\n",
    "SCOPES = [\"https://www.googleapis.com/auth/drive\", \"https://www.googleapis.com/auth/documents\"]\n",
    "SERVICE_ACCOUNT_FILE = \"credentials.json\"\n",
    "\n",
    "def configure_authorization():\n",
    "    os.environ[\"GOOGLE_API_KEY\"] = \"AIzaSyCI8_KdfuDylz1vMOgNwJyAXtof_Gom4jk\"\n",
    "    ngrok.set_auth_token(\"2tWsdY4JT9nt2pWbQnQpEPN4hEp_4p8KQCHZ45JrDMpaRnKo4\")\n",
    "\n",
    "    if 'composio_api_key' not in st.session_state:\n",
    "        st.session_state['composio_api_key'] = 'y0c4nfpdf8c493740x8wru'\n",
    "    if 'serpapi_api_key' not in st.session_state:\n",
    "        st.session_state['serpapi_api_key'] = 'a06f4a4d80f2bdb1e2f808e2bfe0cfe8e8c4bc50767498f1ffa34c91db9425d2'\n",
    "\n",
    "def configure_tools():\n",
    "    composio_toolset = None\n",
    "\n",
    "    try:\n",
    "        composio_toolset = ComposioToolSet(api_key=st.session_state['composio_api_key'])\n",
    "    except Exception as e:\n",
    "        st.error(f\"Error initializing ComposioToolSet: {e}\")\n",
    "        st.stop()\n",
    "\n",
    "    serpApi_toolset = None\n",
    "    try:\n",
    "        serpApi_toolset = SerpApiTools(api_key = st.session_state['serpapi_api_key'])\n",
    "    except Exception as e:\n",
    "        st.error(f\"Error initializing setApi_toolset: {e}\")\n",
    "        st.stop()\n",
    "\n",
    "    google_docs_tool = composio_toolset.get_tools(\n",
    "        actions=[Action.GOOGLEDOCS_CREATE_DOCUMENT]\n",
    "    )[0]\n",
    "    google_docs_tool_update = composio_toolset.get_tools(\n",
    "        actions=[Action.GOOGLEDOCS_UPDATE_EXISTING_DOCUMENT]\n",
    "    )[0]\n",
    "    return google_docs_tool, serpApi_toolset\n",
    "\n",
    "def configure_agent(google_docs_tool, serapi_tool):\n",
    "    professor_agent = Agent(\n",
    "        name=\"Professor\",\n",
    "        role=\"Research and Knowledge Specialist\", \n",
    "        model=Gemini(id=\"gemini-2.0-flash\"), \n",
    "        tools=[google_docs_tool],\n",
    "        instructions=[\n",
    "            \"Create a comprehensive knowledge base that covers fundamental concepts, advanced topics, and current developments of the given topic.\",\n",
    "            \"Exlain the topic from first principles first. Include key terminology, core principles, and practical applications and make it as a detailed report that anyone who's starting out can read and get maximum value out of it.\",\n",
    "            \"Make sure it is formatted in a way that is easy to read and understand. DONT FORGET TO CREATE THE GOOGLE DOCUMENT.\",\n",
    "            \"Open a new Google Doc and write down the response of the agent neatly with great formatting and structure in it. **Include the Google Doc link in your response.**\",\n",
    "        ],\n",
    "        # show_tool_calls=True,\n",
    "        markdown=True,\n",
    "    )\n",
    "\n",
    "    # Create the Academic Advisor agent (formerly RoadmapArchitect)\n",
    "    academic_advisor_agent = Agent(\n",
    "        name=\"Academic Advisor\",\n",
    "        role=\"Learning Path Designer\",\n",
    "        model=Gemini(id=\"gemini-2.0-flash\"),\n",
    "        tools=[google_docs_tool],\n",
    "        instructions=[\n",
    "            \"Using the knowledge base for the given topic, create a detailed learning roadmap.\",\n",
    "            \"Break down the topic into logical subtopics and arrange them in order of progression, a detailed report of roadmap that includes all the subtopics in order to be an expert in this topic.\",\n",
    "            \"Include estimated time commitments for each section.\",\n",
    "            \"Present the roadmap in a clear, structured format. DONT FORGET TO CREATE THE GOOGLE DOCUMENT.\",\n",
    "            \"Open a new Google Doc and write down the response of the agent neatly with great formatting and structure in it. **Include the Google Doc link in your response.**\",\n",
    "\n",
    "        ],\n",
    "        # show_tool_calls=True,\n",
    "        markdown=True\n",
    "    )\n",
    "\n",
    "    # Create the Research Librarian agent (formerly ResourceCurator)\n",
    "    research_librarian_agent = Agent(\n",
    "        name=\"Research Librarian\",\n",
    "        role=\"Learning Resource Specialist\",\n",
    "        model=Gemini(id=\"gemini-2.0-flash\"),\n",
    "        tools=[google_docs_tool, serapi_tool ],\n",
    "        # tools = [SerpApiTools(api_key=st.session_state['serpapi_api_key'])],\n",
    "        instructions=[\n",
    "            \"Make a list of high-quality learning resources for the given topic.\",\n",
    "            \"Use the SerpApi search tool to find current and relevant learning materials.\",\n",
    "            \"Using SerpApi search tool, Include technical blogs, GitHub repositories, official documentation, video tutorials, and courses.\",\n",
    "            \"Present the resources in a curated list with descriptions and quality assessments. DONT FORGET TO CREATE THE GOOGLE DOCUMENT.\",\n",
    "            \"Open a new Google Doc and write down the response of the agent neatly with great formatting and structure in it. **Include the Google Doc link in your response.**\",\n",
    "        ],\n",
    "        # show_tool_calls=True,\n",
    "        markdown=True,\n",
    "    )\n",
    "\n",
    "    # Create the Teaching Assistant agent (formerly PracticeDesigner)\n",
    "    teaching_assistant_agent = Agent(\n",
    "        name=\"Teaching Assistant\",\n",
    "        role=\"Exercise Creator\",\n",
    "        model=Gemini(id=\"gemini-1.5-flash\"),\n",
    "        tools=[google_docs_tool, serapi_tool ],\n",
    "        instructions=[\n",
    "            \"Create comprehensive practice materials for the given topic.\",\n",
    "            \"Use the SerpApi search tool to find example problems and real-world applications.\",\n",
    "            \"Include progressive exercises, quizzes, hands-on projects, and real-world application scenarios.\",\n",
    "            \"Ensure the materials align with the roadmap progression.\",\n",
    "            \"Provide detailed solutions and explanations for all practice materials.DONT FORGET TO CREATE THE GOOGLE DOCUMENT.\",\n",
    "            \"Open a new Google Doc and write down the response of the agent neatly with great formatting and structure in it. **Include the Google Doc link in your response.**\",\n",
    "        ],\n",
    "        # show_tool_calls=True,\n",
    "        markdown=True,\n",
    "    )\n",
    "\n",
    "    return professor_agent, academic_advisor_agent, research_librarian_agent, teaching_assistant_agent\n",
    "\n",
    "def configure_streamlit_page():\n",
    "    st.set_page_config(page_title=\"üë®‚Äçüè´ AI Teaching Agent Team\")\n",
    "    # Streamlit main UI\n",
    "    st.title(\"üë®‚Äçüè´ AI Teaching Agent Team\")\n",
    "    st.markdown(\"Enter a topic to generate a detailed learning path and resources\")\n",
    "\n",
    "    # Add info message about Google Docs\n",
    "    st.info(\"üìù The agents will create detailed Google Docs for each section (Professor, Academic Advisor, Research Librarian, and Teaching Assistant). The links to these documents will be displayed below after processing.\")\n",
    "\n",
    "    # Query bar for topic input\n",
    "    st.session_state['topic'] = st.text_input(\"Enter the topic you want to learn about:\", placeholder=\"e.g., Machine Learning, LoRA, etc.\")\n",
    "\n",
    "def get_google_services():\n",
    "    \"\"\"X√°c th·ª±c Google Docs & Google Drive API\"\"\"\n",
    "    creds = service_account.Credentials.from_service_account_file(\n",
    "        SERVICE_ACCOUNT_FILE, scopes=SCOPES\n",
    "    )\n",
    "    \n",
    "    docs_service = build(\"docs\", \"v1\", credentials=creds)\n",
    "    drive_service = build(\"drive\", \"v3\", credentials=creds)\n",
    "    \n",
    "    return docs_service, drive_service\n",
    "\n",
    "def create_google_doc(docs_service, text):\n",
    "    \"\"\"T·∫°o Google Docs m·ªõi v√† ch√®n vƒÉn b·∫£n\"\"\"\n",
    "    document = docs_service.documents().create(body={\"title\": \"Generated Document\"}).execute()\n",
    "    document_id = document[\"documentId\"]\n",
    "\n",
    "    # Ch√®n vƒÉn b·∫£n v√†o t√†i li·ªáu\n",
    "    requests = [{\"insertText\": {\"location\": {\"index\": 1}, \"text\": text}}]\n",
    "    docs_service.documents().batchUpdate(documentId=document_id, body={\"requests\": requests}).execute()\n",
    "    \n",
    "    return document_id\n",
    "\n",
    "def export_doc_to_pdf(drive_service, document_id):\n",
    "    \"\"\"Xu·∫•t Google Docs th√†nh PDF v√† l·∫•y link t·∫£i\"\"\"\n",
    "    request = drive_service.files().export_media(fileId=document_id, mimeType=\"application/pdf\")\n",
    "    \n",
    "    pdf_filename = f\"{document_id}.pdf\"\n",
    "    with open(pdf_filename, \"wb\") as pdf_file:\n",
    "        pdf_file.write(request.execute())\n",
    "\n",
    "    return pdf_filename\n",
    "\n",
    "def upload_pdf_to_drive(drive_service, pdf_filename):\n",
    "    \"\"\"Upload file PDF l√™n Google Drive v√† l·∫•y link chia s·∫ª\"\"\"\n",
    "    file_metadata = {\"name\": pdf_filename, \"mimeType\": \"application/pdf\"}\n",
    "    media = MediaFileUpload(pdf_filename, mimetype=\"application/pdf\")\n",
    "\n",
    "    uploaded_file = drive_service.files().create(body=file_metadata, media_body=media, fields=\"id\").execute()\n",
    "    file_id = uploaded_file.get(\"id\")\n",
    "\n",
    "    # C·∫•p quy·ªÅn xem file cho m·ªçi ng∆∞·ªùi\n",
    "    permission = {\"role\": \"reader\", \"type\": \"anyone\"}\n",
    "    drive_service.permissions().create(fileId=file_id, body=permission).execute()\n",
    "\n",
    "    # L·∫•y link truy c·∫≠p file\n",
    "    file_link = f\"https://drive.google.com/file/d/{file_id}/view\"\n",
    "    return file_link\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def runner(professor_agent, academic_advisor_agent, research_librarian_agent, teaching_assistant_agent):\n",
    "    # Start button\n",
    "    if st.button(\"Start\"):\n",
    "        if not st.session_state['topic']:\n",
    "            st.error(\"Please enter a topic.\")\n",
    "        else:\n",
    "            # Display loading animations while generating responses\n",
    "            with st.spinner(\"Generating Knowledge Base...\"):\n",
    "                professor_response: RunResponse = professor_agent.run(\n",
    "                    f\"the topic is: {st.session_state['topic']},Don't forget to add the Google Doc link in your response.\",\n",
    "                    stream=False\n",
    "                )\n",
    "\n",
    "                docs_service, drive_service = get_google_services()\n",
    "    \n",
    "                # N·ªôi dung c·∫ßn xu·∫•t\n",
    "                text_content = \"This is a sample document generated using Google Docs API and converted to PDF.\"\n",
    "\n",
    "                # B∆∞·ªõc 1: T·∫°o Google Docs\n",
    "                document_id = create_google_doc(docs_service, text_content)\n",
    "\n",
    "                # B∆∞·ªõc 2: Xu·∫•t file PDF\n",
    "                pdf_file = export_doc_to_pdf(drive_service, document_id)\n",
    "\n",
    "                # B∆∞·ªõc 3: Upload l√™n Google Drive & L·∫•y link\n",
    "                pdf_link = upload_pdf_to_drive(drive_service, pdf_file)\n",
    "\n",
    "                print(f\"‚úÖ PDF Link: {pdf_link}\")\n",
    "                \n",
    "            # with st.spinner(\"Generating Learning Roadmap...\"):\n",
    "            #     academic_advisor_response: RunResponse = academic_advisor_agent.run(\n",
    "            #         f\"the topic is: {st.session_state['topic']},Don't forget to add the Google Doc link in your response.\",\n",
    "            #         stream=False\n",
    "            #     )\n",
    "                \n",
    "            # with st.spinner(\"Finding Learning Resources...\"):\n",
    "            #     research_librarian_response: RunResponse = research_librarian_agent.run(\n",
    "            #         f\"the topic is: {st.session_state['topic']},Don't forget to add the Google Doc link in your response.\",\n",
    "            #         stream=False\n",
    "            #     )\n",
    "                \n",
    "            # with st.spinner(\"Creating Practice Materials...\"):\n",
    "            #     teaching_assistant_response: RunResponse = teaching_assistant_agent.run(\n",
    "            #         f\"the topic is: {st.session_state['topic']},Don't forget to add the Google Doc link in your response.\",\n",
    "            #         stream=False\n",
    "            #     )\n",
    "\n",
    "            with st.spinner(\"Creating PDF file...\"):\n",
    "                    docs_service, drive_service = get_google_services()\n",
    "\n",
    "                    # N·ªôi dung c·∫ßn xu·∫•t\n",
    "                    text_content = \"\"\n",
    "                    if professor_response.content is not None:\n",
    "                        text_content.join(professor_response.content).join(\"\\n\")\n",
    "                    # if academic_advisor_response is not None:\n",
    "                    #     text_content.join(academic_advisor_response.content + \"\\n\")\n",
    "                    # if research_librarian_response is not None:\n",
    "                    #     text_content.join(research_librarian_response.content + \"\\n\")\n",
    "                    # if teaching_assistant_response is not None:\n",
    "                    #     text_content.join(teaching_assistant_response.content)\n",
    "\n",
    "                    if text_content == \"\":\n",
    "                        text_content = \"None\"\n",
    "                    # B∆∞·ªõc 1: T·∫°o Google Docs\n",
    "                    document_id = create_google_doc(docs_service, text_content)\n",
    "\n",
    "                    # B∆∞·ªõc 2: Xu·∫•t file PDF\n",
    "                    pdf_file = export_doc_to_pdf(drive_service, document_id)\n",
    "\n",
    "                    # B∆∞·ªõc 3: Upload l√™n Google Drive & L·∫•y link\n",
    "                    pdf_link = upload_pdf_to_drive(drive_service, pdf_file)\n",
    "            \n",
    "            def extract_google_doc_link(response_content):\n",
    "                if response_content is None: \n",
    "                    return None\n",
    "                if \"https://docs.google.com\" in response_content:\n",
    "                    return response_content.split(\"https://docs.google.com\")[1].split()[0].split(\"/edit\")[0].split(\")\")[0].split(\"]\")[0] + \"/edit\"\n",
    "                return None\n",
    "\n",
    "            professor_doc_link = extract_google_doc_link(professor_response.content)\n",
    "            # academic_advisor_doc_link = extract_google_doc_link(academic_advisor_response.content)\n",
    "            # research_librarian_doc_link = extract_google_doc_link(research_librarian_response.content)\n",
    "            # teaching_assistant_doc_link = extract_google_doc_link(teaching_assistant_response.content)\n",
    "\n",
    "            # Display Google Doc links at the top of the Streamlit UI\n",
    "            st.markdown(\"### Google Doc Links:\")\n",
    "            if professor_doc_link:\n",
    "                st.markdown(f\"- **Professor Document:** [View Document](https://docs.google.com{professor_doc_link})\")\n",
    "            # if academic_advisor_doc_link:\n",
    "            #     st.markdown(f\"- **Academic Advisor Document:** [View Document](https://docs.google.com{academic_advisor_doc_link})\")\n",
    "            # if research_librarian_doc_link:\n",
    "            #     st.markdown(f\"- **Research Librarian Document:** [View Document](https://docs.google.com{research_librarian_doc_link})\")\n",
    "            # if teaching_assistant_doc_link:\n",
    "            #     st.markdown(f\"- **Teaching Assistant Document:** [View Document](https://docs.google.com{teaching_assistant_doc_link})\")\n",
    "\n",
    "            st.markdown(\"### PDF File Link:\")\n",
    "            st.markdown(f\"- **PDF:** [View Document]({pdf_link})\")\n",
    "\n",
    "            # Display responses in the Streamlit UI using pprint_run_response\n",
    "            st.markdown(\"### Professor Response:\")\n",
    "            st.markdown(professor_response.content)\n",
    "            pprint_run_response(professor_response, markdown=True)\n",
    "            st.divider()\n",
    "            \n",
    "            # st.markdown(\"### Academic Advisor Response:\")\n",
    "            # st.markdown(academic_advisor_response.content)\n",
    "            # pprint_run_response(academic_advisor_response, markdown=True)\n",
    "            # st.divider()\n",
    "\n",
    "            # st.markdown(\"### Research Librarian Response:\")\n",
    "            # st.markdown(research_librarian_response.content)\n",
    "            # pprint_run_response(research_librarian_response, markdown=True)\n",
    "            # st.divider()\n",
    "\n",
    "            # st.markdown(\"### Teaching Assistant Response:\")\n",
    "            # st.markdown(teaching_assistant_response.content)\n",
    "            # pprint_run_response(teaching_assistant_response, markdown=True)\n",
    "            st.divider()\n",
    "    # Information about the agents\n",
    "    st.markdown(\"---\")\n",
    "    st.markdown(\"### About the Agents:\")\n",
    "    st.markdown(\"\"\"\n",
    "    - **Professor**: Researches the topic and creates a detailed knowledge base.\n",
    "    - **Academic Advisor**: Designs a structured learning roadmap for the topic.\n",
    "    - **Research Librarian**: Curates high-quality learning resources.\n",
    "    - **Teaching Assistant**: Creates practice materials, exercises, and projects.\n",
    "    \"\"\")\n",
    "\n",
    "\n",
    "def create_ngrok_link():\n",
    "    public_url = ngrok.connect(8501)\n",
    "    print(f\"Public URL: {public_url}\")\n",
    "    return public_url\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    create_ngrok_link()\n",
    "\n",
    "    configure_authorization()\n",
    "\n",
    "    google_doc_tool, serapi_tool = configure_tools()\n",
    "\n",
    "    configure_streamlit_page()\n",
    "\n",
    "    professor, advisor, librarian, ta = configure_agent(google_doc_tool, serapi_tool)\n",
    "\n",
    "    runner(professor_agent=professor, academic_advisor_agent= advisor, research_librarian_agent=librarian, teaching_assistant_agent=ta)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
